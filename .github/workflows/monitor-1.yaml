# name: SageMaker Model Monitor (Iris) - Production

# on:
#   workflow_dispatch:

# jobs:
#   model_monitor:
#     runs-on: ubuntu-latest

#     env:
#       AWS_REGION: us-east-1

#       # Your endpoint + role
#       ENDPOINT_NAME: iris-endpoint
#       SAGEMAKER_EXEC_ROLE_ARN: arn:aws:iam::387867038403:role/AqeelIrisSageMakerExecutionRole

#       # Buckets / paths
#       S3_BUCKET: sagemaker-aqeel-iris-us-east-1-387867038403
#       DATACAPTURE_S3_URI: s3://sagemaker-aqeel-iris-us-east-1-387867038403/monitoring/datacapture/

#       # Baseline dataset (features only, header=True)
#       # BASELINE_DATASET_S3_URI: s3://sagemaker-aqeel-iris-us-east-1-387867038403/datasets/iris/features.csv
#       BASELINE_DATASET_S3_URI: s3://sagemaker-aqeel-iris-us-east-1-387867038403/datasets/iris/baseline/features.csv
#       BASELINE_OUTPUT_S3_URI: s3://sagemaker-aqeel-iris-us-east-1-387867038403/monitoring/baseline/

#       # Model Monitor reports
#       REPORTS_S3_URI: s3://sagemaker-aqeel-iris-us-east-1-387867038403/monitoring/reports

#       # Monitoring schedule
#       SCHEDULE_NAME: aqeel-iris-model-monitor
#       CRON: "cron(0 * ? * * *)"
#       PROCESSING_INSTANCE_TYPE: ml.t3.large

#       # Alerting (SNS topic name)
#       SNS_TOPIC_NAME: aqeel-iris-drift-alerts

#     steps:
#       - name: Checkout
#         uses: actions/checkout@v4

#       - name: Configure AWS Credentials
#         uses: aws-actions/configure-aws-credentials@v4
#         with:
#           aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
#           aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
#           aws-region: ${{ env.AWS_REGION }}

#       - name: Setup Python
#         uses: actions/setup-python@v5
#         with:
#           python-version: "3.11"

#       - name: Install dependencies
#         run: |
#           python -m pip install --upgrade pip
#           pip install -r monitoring/requirements.txt

#       # 1) Enable DataCapture on the endpoint (idempotent)
#       - name: Enable Data Capture (EndpointConfig update)
#         run: |
#           python monitoring/enable_data_capture.py \
#             --region "${{ env.AWS_REGION }}" \
#             --endpoint-name "${{ env.ENDPOINT_NAME }}" \
#             --capture-s3-uri "${{ env.DATACAPTURE_S3_URI }}" \
#             --sampling-percentage 100

#       # 2) Create / refresh baseline (statistics.json + constraints.json)
#       - name: Create/Update Baseline (Model Monitor)
#         run: |
#           python monitoring/mm_create_baseline.py \
#             --region "${{ env.AWS_REGION }}" \
#             --role-arn "${{ env.SAGEMAKER_EXEC_ROLE_ARN }}" \
#             --baseline-data-s3-uri "${{ env.BASELINE_DATASET_S3_URI }}" \
#             --baseline-output-s3-uri "${{ env.BASELINE_OUTPUT_S3_URI }}" \
#             --instance-type "${{ env.PROCESSING_INSTANCE_TYPE }}"

#       # 3) Create / recreate monitoring schedule
#       - name: Create/Update Monitoring Schedule (Model Monitor)
#         run: |
#           python monitoring/mm_create_schedule.py \
#             --region "${{ env.AWS_REGION }}" \
#             --role-arn "${{ env.SAGEMAKER_EXEC_ROLE_ARN }}" \
#             --endpoint-name "${{ env.ENDPOINT_NAME }}" \
#             --schedule-name "${{ env.SCHEDULE_NAME }}" \
#             --baseline-s3-uri "${{ env.BASELINE_OUTPUT_S3_URI }}" \
#             --monitor-output-s3-uri "${{ env.REPORTS_S3_URI }}" \
#             --datacapture-s3-uri "${{ env.DATACAPTURE_S3_URI }}" \
#             --cron "${{ env.CRON }}" \
#             --instance-type "${{ env.PROCESSING_INSTANCE_TYPE }}" \
#             --instance-count 1 \
#             --volume-size 50 \
#             --max-runtime 1800

#       # 4) Create SNS + CloudWatch alarm for drift (constraint violations)
#       # IMPORTANT: add GitHub secret ALERT_EMAIL (your email) and confirm subscription from inbox.
#       - name: Create Drift Alarm (CloudWatch + SNS)
#         run: |
#           python monitoring/mm_create_drift_alarm.py \
#             --region "${{ env.AWS_REGION }}" \
#             --schedule-name "${{ env.SCHEDULE_NAME }}" \
#             --endpoint-name "${{ env.ENDPOINT_NAME }}" \
#             --sns-topic-name "${{ env.SNS_TOPIC_NAME }}" \
#             --email "aqeel.sadiq3456@gmail.com"



#       # - name: Create Drift Alarm (CloudWatch + SNS)
#       #   run: |
#       #     python monitoring/mm_create_drift_alarm.py \
#       #       --region "${{ env.AWS_REGION " \
#       #       --schedule-name "${{ env.SCHEDULE_NAME " \
#       #       --sns-topic-name "${{ env.SNS_TOPIC_NAME " \
#       #       --email "aqeel.sadiq3456@gmail.com"





#claude code
name: Setup Model Monitoring (Iris)

on:
  workflow_dispatch:

jobs:
  monitoring:
    runs-on: ubuntu-latest

    env:
      AWS_REGION: us-east-1

      ENDPOINT_NAME: iris-endpoint
      SCHEDULE_NAME: aqeel-iris-model-monitor

      # Your execution role
      SAGEMAKER_EXEC_ROLE_ARN: arn:aws:iam::387867038403:role/AqeelIrisSageMakerExecutionRole

      # S3 paths (update if needed)
      DATACAPTURE_S3_URI: s3://sagemaker-aqeel-iris-us-east-1-387867038403/monitoring/datacapture/
      BASELINE_DATA_S3_URI: s3://sagemaker-aqeel-iris-us-east-1-387867038403/data/features.csv
      BASELINE_OUTPUT_S3_URI: s3://sagemaker-aqeel-iris-us-east-1-387867038403/monitoring/baseline/
      REPORTS_OUTPUT_S3_URI: s3://sagemaker-aqeel-iris-us-east-1-387867038403/monitoring/reports/
      PREPROCESSOR_S3_PREFIX: s3://sagemaker-aqeel-iris-us-east-1-387867038403/monitoring/scripts/

      # alerts
      SNS_TOPIC_NAME: aqeel-iris-monitor-alerts
      ALERT_EMAIL: aqeel.sadiq3456@gmail.com

      # schedule
      CRON_EXPR: cron(0 * ? * * *)   # every 5 minutes (your example)

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"


      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip uninstall -y sagemaker || true
          pip install "sagemaker>=2.220.0" boto3 botocore
          python -c "import sagemaker; print('sagemaker version:', sagemaker.__version__)"

      - name: Enable Data Capture
        run: |
          python monitoring/enable_data_capture.py \
            --region "$AWS_REGION" \
            --endpoint-name "$ENDPOINT_NAME" \
            --capture-s3-uri "$DATACAPTURE_S3_URI" \
            --sampling-percentage 100

      - name: Create Baseline (writes statistics.json + constraints.json)
        run: |
          python monitoring/mm_create_baseline.py \
            --region "$AWS_REGION" \
            --role-arn "$SAGEMAKER_EXEC_ROLE_ARN" \
            --baseline-data-s3-uri "$BASELINE_DATA_S3_URI" \
            --baseline-output-s3-uri "$BASELINE_OUTPUT_S3_URI" \
            --preprocessor-local-path "./monitoring/record_preprocessor.py" \
            --preprocessor-s3-prefix "$PREPROCESSOR_S3_PREFIX" \
            --instance-type "ml.t3.xlarge" \
            --instance-count 1

      - name: Create Monitoring Schedule
        run: |
          python monitoring/mm_create_schedule.py \
            --region "$AWS_REGION" \
            --role-arn "$SAGEMAKER_EXEC_ROLE_ARN" \
            --endpoint-name "$ENDPOINT_NAME" \
            --schedule-name "$SCHEDULE_NAME" \
            --baseline-s3-uri "$BASELINE_OUTPUT_S3_URI" \
            --monitor-output-s3-uri "$REPORTS_OUTPUT_S3_URI" \
            --preprocessor-s3-uri "${PREPROCESSOR_S3_PREFIX%/}/record_preprocessor.py" \
            --cron "$CRON_EXPR" \
            --instance-type "ml.t3.xlarge" \
            --instance-count 1

      - name: Create Constraint Violation Alarm (Email)
        run: |
          python monitoring/mm_create_constraints_alarm.py \
            --region "$AWS_REGION" \
            --endpoint-name "$ENDPOINT_NAME" \
            --schedule-name "$SCHEDULE_NAME" \
            --sns-topic-name "$SNS_TOPIC_NAME" \
            --email "$ALERT_EMAIL" \
            --period 300 \
            --eval-periods 1 \
            --threshold 1