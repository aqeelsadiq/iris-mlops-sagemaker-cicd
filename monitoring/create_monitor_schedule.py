import argparse
import boto3
import sagemaker
from sagemaker.model_monitor import DefaultModelMonitor
from sagemaker.session import Session

def parse_args():
    p = argparse.ArgumentParser()
    p.add_argument("--region", required=True)
    p.add_argument("--role-arn", required=True)
    p.add_argument("--default-bucket", required=True)

    p.add_argument("--endpoint-name", required=True)
    p.add_argument("--schedule-name", required=True)

    p.add_argument("--baseline-s3-uri", required=True)  # the folder where constraints/statistics are stored
    p.add_argument("--monitor-output-s3-uri", required=True)  # s3://.../monitoring/reports/

    # cron: every hour
    p.add_argument("--cron", default="cron(0 * ? * * *)")
    return p.parse_args()

def main():
    args = parse_args()

    boto_sess = boto3.Session(region_name=args.region)
    sm_sess = sagemaker.Session(boto_session=boto_sess, default_bucket=args.default_bucket)

    monitor = DefaultModelMonitor(
        role=args.role_arn,
        instance_count=1,
        instance_type="ml.m5.large",
        volume_size_in_gb=20,
        max_runtime_in_seconds=3600,
        sagemaker_session=sm_sess
    )

    # Load constraints/statistics generated by suggest_baseline
    monitor.latest_baselining_job_name  # not required, just ensuring object exists

    monitor.create_monitoring_schedule(
        monitor_schedule_name=args.schedule_name,
        endpoint_input=sagemaker.model_monitor.EndpointInput(
            endpoint_name=args.endpoint_name,
            destination="/opt/ml/processing/input",
        ),
        output_s3_uri=args.monitor_output_s3_uri,
        statistics=monitor.baseline_statistics(),   # reads from local config if set
        constraints=monitor.baseline_constraints(), # reads from local config if set
        schedule_cron_expression=args.cron,
    )

    print("âœ… Monitoring schedule created:", args.schedule_name)
    print("   Reports will be in:", args.monitor_output_s3_uri)

if __name__ == "__main__":
    main()
